# dblstreamgen - Kinesis Configuration for Databricks
# AWS Kinesis Data Streams publisher configuration

source_type: "kinesis"

kinesis_config:
  # Kinesis stream name
  stream_name: "YOUR_STREAM_NAME"  # ← CHANGE THIS
  
  # AWS region
  region: "us-east-1"  # ← CHANGE THIS if needed
  
  # Partition key field - must match a field name from common_fields or event fields
  # This determines how events are distributed across Kinesis shards
  # Default: "event_type_id" if not specified
  partition_key_field: "player_id"  # ← CHANGE THIS to match your primary identifier
  
  # AWS credentials - USE DATABRICKS SECRETS!
  # Option 1: Reference Databricks secrets (RECOMMENDED)
  # Create secrets with:
  #   databricks secrets create-scope --scope dblstreamgen
  #   databricks secrets put --scope dblstreamgen --key aws-access-key
  #   databricks secrets put --scope dblstreamgen --key aws-secret-key
  
  # Then uncomment these lines:
  # aws_access_key_id: "{{secrets/dblstreamgen/aws-access-key}}"
  # aws_secret_access_key: "{{secrets/dblstreamgen/aws-secret-key}}"
  
  # Option 2: Use IAM role (if Databricks cluster has IAM role attached)
  # Leave aws_access_key_id and aws_secret_access_key commented out
  
  # Batch size for PutRecords API (max 500)
  batch_size: 500

# Note: The library will automatically resolve {{secrets/...}} references
# using dbutils.secrets.get() when running in Databricks

